{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.MNIST, Images\n",
    "using Flux: onehotbatch, argmax, mse, throttle\n",
    "using Base.Iterators: partition\n",
    "using Images\n",
    "#using CuArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model we'll learn a compression scheme. The idea is to encode MNIST digits as small vectors that can then be decoded back into the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = MNIST.images()\n",
    "vecs = float.(vec.(imgs))\n",
    "\n",
    "# Partition into batches of size 1000\n",
    "data = [gpu(hcat(vecs[i]...)) for i in partition(1:60_000, 1000)];\n",
    "vecs = gpu.(vecs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 32 # Size of the encoding\n",
    "\n",
    "encoder = Dense(28^2, N, relu)\n",
    "decoder = Dense(N, 28^2, relu)\n",
    "\n",
    "m = gpu(Chain(encoder, decoder))\n",
    "\n",
    "loss(x) = mse(m(x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to be able to visualise what's happening in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray(x) = Gray(x)\n",
    "img(x::AbstractVector) = collect(gray.(reshape(clamp.(x, 0, 1), 28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round-trip through the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img(m(vecs[1]).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random selection of 20 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sample()\n",
    "  # 20 random digits\n",
    "  xs = [vecs[i] for i in rand(1:length(imgs), 20)]\n",
    "  # Before and after images\n",
    "  before, after = img.(xs), img.(map(x -> m(x).data, xs))\n",
    "  # Stack them all together\n",
    "  hcat(vcat.(before, after)...)\n",
    "end\n",
    "sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evalcb = function ()\n",
    "    print_with_color(:blue, \"Loss is $(loss(data[1][1]))\")\n",
    "    display(sample())\n",
    "end\n",
    "opt = ADAM(params(m))\n",
    "\n",
    "for i = 1:10\n",
    "    Flux.train!(loss, zip(data), opt)\n",
    "    evalcb()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2-pre",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
